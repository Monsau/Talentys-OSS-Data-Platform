# ğŸš€ Quick Start Guide - Data Platform v1.0

## ğŸ“¦ One-Command Launch

### Option 1: Automatic Orchestration (Recommended)

Use the **orchestrate_platform.py** script for automatic deployment with all configurations:

```bash
# Windows PowerShell
$env:PYTHONIOENCODING="utf-8"
python -u orchestrate_platform.py

# Linux/Mac
python orchestrate_platform.py
```

**What it does:**
- âœ… Checks prerequisites (Docker, Docker Compose, Python)
- âœ… Starts all Docker services (Dremio, PostgreSQL, MinIO, Elasticsearch)
- âœ… Launches Airbyte for data integration
- âœ… Configures dbt environment
- âœ… Runs dbt models and tests
- âœ… Synchronizes Dremio data to PostgreSQL
- âœ… Creates Superset dashboards automatically
- âœ… Generates Open Data dashboard

**Options:**
```bash
# Show help
python orchestrate_platform.py --help

# Skip infrastructure deployment (if already running)
python orchestrate_platform.py --skip-infrastructure

# Custom workspace path
python orchestrate_platform.py --workspace /path/to/workspace
```

### Option 2: Manual Docker Launch

Start services manually:

```bash
# Start main stack
docker-compose up -d

# Start with Airbyte
docker-compose -f docker-compose.yml -f docker-compose-airbyte-stable.yml up -d
```

---

## ğŸŒ Access Services

| Service | URL | Credentials |
|---------|-----|-------------|
| **Airbyte** | http://localhost:8000 | Setup wizard |
| **Dremio** | http://localhost:9047 | Create account |
| **Superset** | http://localhost:8088 | admin / admin |
| **Airflow** | http://localhost:8080 | airflow / airflow |
| **MinIO** | http://localhost:9001 | minioadmin / minioadmin |
| **OpenMetadata** | http://localhost:8585 | admin / admin |

---

## ğŸ”Œ Dremio PostgreSQL Proxy

Connect any PostgreSQL client to Dremio:

```bash
# psql
psql -h localhost -p 31010 -U <your-dremio-username>

# Python
import psycopg2
conn = psycopg2.connect(
    host="localhost",
    port=31010,
    user="your-dremio-username",
    password="your-dremio-password",
    database="Dremio"
)
```

---

## ğŸ”„ Airbyte - Data Integration

**Access**: http://localhost:8000

### Quick Setup

1. **Create Source** (e.g., PostgreSQL):
   - Host: `dremio-postgres`
   - Port: `5432`
   - Database: `business_db`
   - User: `postgres`
   - Password: `postgres123`

2. **Create Destination** (e.g., MinIO S3):
   - Endpoint: `http://dremio-minio:9000`
   - Access Key: `minioadmin`
   - Secret Key: `minioadmin`
   - Bucket: `datalake`
   - Path: `bronze/<source>/`

3. **Create Connection**:
   - Select streams/tables
   - Choose sync mode (Full Refresh / Incremental / CDC)
   - Set schedule (manual, hourly, daily, etc.)

### Sync Modes

- **Full Refresh**: Complete data reload
- **Incremental Append**: Only new/changed records (requires cursor field)
- **CDC**: Real-time change capture (for databases)

---

## ğŸ”ï¸ Dremio - Lakehouse

**Access**: http://localhost:9047

### Quick Setup

1. **Create Account** (first time)
2. **Add Sources**:
   - PostgreSQL: `dremio-postgres:5432`
   - MinIO S3: `http://dremio-minio:9000`
   - Elasticsearch: `http://dremio-elasticsearch:9200`

3. **Query Data**:
```sql
-- Query from PostgreSQL
SELECT * FROM postgres.business_db.customers LIMIT 10;

-- Query from MinIO (Parquet files)
SELECT * FROM s3.bronze.sales.sales_data LIMIT 10;

-- Join across sources
SELECT 
    c.customer_name,
    s.total_amount
FROM postgres.business_db.customers c
JOIN s3.bronze.sales.sales_data s ON c.id = s.customer_id;
```

---

## ğŸ“Š End-to-End Data Pipeline

### Example: E-commerce Analytics

```
1. SOURCE DATA (PostgreSQL)
   â”œâ”€â”€ customers (id, name, email, country)
   â”œâ”€â”€ orders (id, customer_id, order_date, total)
   â””â”€â”€ products (id, name, category, price)

2. AIRBYTE â†’ Extract & Load
   â”œâ”€â”€ Sync to MinIO S3 (Bronze layer)
   â”‚   â””â”€â”€ s3://datalake/bronze/ecommerce/
   â”‚       â”œâ”€â”€ customers/
   â”‚       â”œâ”€â”€ orders/
   â”‚       â””â”€â”€ products/
   â””â”€â”€ Sync mode: Incremental (every 6 hours)

3. DREMIO â†’ Query & Transform
   â”œâ”€â”€ Mount MinIO as data source
   â”œâ”€â”€ Create Virtual Datasets
   â””â”€â”€ Apply Reflections (query acceleration)

4. DBT â†’ Transform (Silver â†’ Gold)
   â”œâ”€â”€ models/silver/
   â”‚   â”œâ”€â”€ stg_customers.sql (cleaned)
   â”‚   â”œâ”€â”€ stg_orders.sql (cleaned)
   â”‚   â””â”€â”€ stg_products.sql (cleaned)
   â””â”€â”€ models/gold/
       â”œâ”€â”€ dim_customers.sql (dimension)
       â”œâ”€â”€ dim_products.sql (dimension)
       â””â”€â”€ fact_orders.sql (fact table)

5. SUPERSET â†’ Visualize
   â”œâ”€â”€ Connect to Dremio (port 31010)
   â”œâ”€â”€ Create datasets from Gold layer
   â””â”€â”€ Build dashboards
       â”œâ”€â”€ Sales Overview
       â”œâ”€â”€ Customer Analytics
       â””â”€â”€ Product Performance

6. AIRFLOW â†’ Orchestrate
   â””â”€â”€ DAG: ecommerce_pipeline
       â”œâ”€â”€ Trigger Airbyte sync
       â”œâ”€â”€ Wait for completion
       â”œâ”€â”€ Run dbt transformations
       â””â”€â”€ Refresh Superset dashboards
```

---

## ğŸ“ˆ Typical Workflows

### 1. Batch ETL (Daily/Hourly)
```
Airbyte (Full Refresh) 
  â†’ MinIO Bronze
  â†’ Dremio Query
  â†’ dbt Transform
  â†’ Superset Dashboard
```

### 2. Real-time CDC
```
Database (CDC enabled)
  â†’ Airbyte (CDC mode)
  â†’ MinIO Bronze
  â†’ Dremio (live query)
  â†’ Superset (auto-refresh)
```

### 3. Data Lake Analytics
```
Multiple Sources
  â†’ Airbyte
  â†’ MinIO (Parquet/Iceberg)
  â†’ Dremio (federated queries)
  â†’ BI Tools
```

---

## ğŸ› ï¸ Maintenance

### Check Status
```bash
docker ps
```

### View Logs
```bash
docker logs <container_name>
```

### Restart Service
```bash
docker restart <container_name>
```

### Stop All
```bash
docker-compose -f docker-compose.yml -f docker-compose-airbyte-stable.yml down
```

### Clean Restart
```bash
docker-compose down -v  # Remove volumes
docker-compose -f docker-compose.yml -f docker-compose-airbyte-stable.yml up -d
```

---

## ğŸ“š Documentation

- **Full Guide**: [PLATFORM_STATUS.md](PLATFORM_STATUS.md)
- **README**: [README.md](README.md) (18 languages)
- **Architecture**: [docs/diagrams/](docs/diagrams/)
- **Examples**: [examples/](examples/)

---

## ğŸŒ Repository

**GitHub**: https://github.com/Monsau/data-platform-iso-opensource  
**Version**: 1.0.0  
**License**: MIT  
**Author**: Mustapha Fonsau (mfonsau@talentys.eu)  
**Organization**: [Talentys](https://talentys.eu)

---

**Ready to go!** ğŸ‰

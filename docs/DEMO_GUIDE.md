# üé¨ Guide de D√©monstration - Dremio Sandbox

**Objectif**: Pr√©senter la sandbox en 15 minutes avec un impact maximal

**Public cible**: D√©cideurs, Data Engineers, Analystes BI

**Message cl√©**: "Dremio simplifie l'acc√®s aux donn√©es h√©t√©rog√®nes avec dbt pour la gouvernance"

---

## üìã Pr√©paration (5 minutes avant la d√©mo)

### Checklist Pr√©-D√©mo

- [ ] Tous les services Docker sont "Up" (`docker-compose ps`)
- [ ] Dremio accessible sur http://localhost:9047
- [ ] dbt docs g√©n√©r√©s (`dbt docs generate`)
- [ ] Donn√©es popul√©es (2,425+ records au total)
- [ ] Navigateur avec 4 onglets ouverts:
  - Tab 1: Dremio SQL Runner (http://localhost:9047)
  - Tab 2: dbt Docs (http://localhost:8080)
  - Tab 3: MinIO Console (http://localhost:9001)
  - Tab 4: Elasticsearch (http://localhost:9200)
- [ ] Script SQL de d√©mo pr√©par√© dans un √©diteur
- [ ] √âcran partag√© pr√™t (si pr√©sentation en visio)

### Environnement Recommand√©

```
üì∫ √âcran: 1920x1080 minimum
üñ•Ô∏è R√©solution partag√©e: 1280x720
üé§ Micro test√©
üí° Mode sombre activ√© (moins fatigant)
‚ö° Requ√™tes SQL pr√©-test√©es
```

---

## üéØ Structure de la D√©mo (15 minutes)

### Phase 1: Introduction (2 min)
**Objectif**: Poser le contexte et les enjeux

### Phase 2: Sources de Donn√©es (3 min)
**Objectif**: Montrer l'h√©t√©rog√©n√©it√© des sources

### Phase 3: Virtualisation Dremio (4 min)
**Objectif**: D√©montrer la valeur de Dremio (query pushdown, no ETL)

### Phase 4: Pipeline dbt (3 min)
**Objectif**: Gouvernance et qualit√© des donn√©es

### Phase 5: Cas d'Usage Business (3 min)
**Objectif**: R√©soudre un probl√®me m√©tier r√©el

---

## üìñ Script D√©taill√©

### üé¨ PHASE 1: Introduction (2 min)

#### Slide 1: Le Probl√®me

> "**Le d√©fi actuel**: Les √©quipes Data jonglent avec des donn√©es √©parpill√©es dans plusieurs syst√®mes. PostgreSQL pour les transactions, un Data Lake MinIO pour l'historique, Elasticsearch pour les logs. R√©sultat? Des ETL complexes, des copies de donn√©es, des silos."

**Visuel**: Sch√©ma avec sources s√©par√©es et fl√®ches complexes

#### Slide 2: La Solution

> "**Notre approche Modern Data Stack**: Dremio comme couche de virtualisation + dbt pour la gouvernance. Pas de copie, pas d'ETL, juste du SQL."

**Visuel**: Architecture simple (sources ‚Üí Dremio ‚Üí dbt ‚Üí BI)

---

### üé¨ PHASE 2: Sources de Donn√©es (3 min)

#### D√©mo 2.1: PostgreSQL (45 sec)

**Narratif**:
> "Commen√ßons par notre base transactionnelle PostgreSQL. Ici, nos commandes clients et informations clients."

**Action**: Ouvrir Dremio ‚Üí Sources ‚Üí PostgreSQL_BusinessDB

**SQL √† ex√©cuter**:
```sql
-- Aper√ßu des commandes r√©centes
SELECT 
    o.order_id,
    c.customer_name,
    o.order_amount,
    o.order_date,
    o.order_status
FROM "PostgreSQL_BusinessDB".public.orders o
JOIN "PostgreSQL_BusinessDB".public.customers c 
    ON o.customer_id = c.customer_id
ORDER BY o.order_date DESC
LIMIT 10;
```

**Point cl√©**:
> "PostgreSQL, parfait pour les transactions OLTP, mais limit√© pour l'analytique historique."

---

#### D√©mo 2.2: MinIO Data Lake (45 sec)

**Narratif**:
> "Pour l'historique long terme, nous utilisons MinIO comme Data Lake. 550 fichiers Parquet partitionn√©s par date."

**Action**: Montrer MinIO Console (http://localhost:9001)
- Naviguer dans le bucket `sales-data`
- Montrer la structure `year/month/day/`

**SQL √† ex√©cuter**:
```sql
-- Requ√™te sur le Data Lake (pushdown vers Parquet)
SELECT 
    year,
    month,
    COUNT(*) as total_sales,
    SUM(amount) as revenue,
    AVG(amount) as avg_sale
FROM minio_sales."sales-data".sales
WHERE year = 2024
GROUP BY year, month
ORDER BY month;
```

**Point cl√©**:
> "Dremio lit directement les Parquet sans copie. Query pushdown = performance optimale."

---

#### D√©mo 2.3: Elasticsearch (45 sec)

**Narratif**:
> "Pour le monitoring temps r√©el, Elasticsearch centralise logs, √©v√©nements utilisateur, et m√©triques syst√®me."

**Action**: V√©rifier ES health
```powershell
curl http://localhost:9200/_cat/indices?v
```

**SQL √† ex√©cuter** (syntaxe Dremio 26):
```sql
-- Logs d'erreur de la derni√®re heure
SELECT 
    "timestamp",
    service,
    log_level,
    message,
    environment
FROM elasticsearch.application_logs."_doc"
WHERE log_level = 'ERROR'
  AND "timestamp" >= CURRENT_TIMESTAMP - INTERVAL '1' HOUR
ORDER BY "timestamp" DESC
LIMIT 10;
```

**Point cl√©**:
> "Notez la syntaxe sp√©ciale Dremio 26: ."_doc" pour les indices Elasticsearch 7.x"

---

### üé¨ PHASE 3: Virtualisation Dremio (4 min)

#### D√©mo 3.1: Cr√©ation de VDS en Live (1 min)

**Narratif**:
> "Cr√©ons un Virtual Dataset combinant PostgreSQL et Elasticsearch, SANS copier les donn√©es."

**SQL √† ex√©cuter**:
```sql
-- VDS: Vue unifi√©e Client + Activit√©
CREATE VDS raw.customer_activity AS
SELECT 
    c.customer_id,
    c.customer_name,
    c.email,
    COUNT(e.event_type) as total_events,
    SUM(CASE WHEN e.is_purchase = 1 THEN 1 ELSE 0 END) as purchases,
    MAX(e."timestamp") as last_activity
FROM "PostgreSQL_BusinessDB".public.customers c
LEFT JOIN elasticsearch.user_events."_doc" e
    ON CAST(c.customer_id AS VARCHAR) = e.user_id
GROUP BY c.customer_id, c.customer_name, c.email;
```

**Action**: Cliquer sur **Save As** ‚Üí `raw.customer_activity`

**Point cl√©**:
> "Dremio optimise cette requ√™te: JOIN ex√©cut√© c√¥t√© engine, pas de mouvement de donn√©es!"

---

#### D√©mo 3.2: Query Performance (1 min)

**Narratif**:
> "Testons la performance sur le Data Lake MinIO avec 550 fichiers Parquet."

**SQL √† ex√©cuter**:
```sql
-- Agr√©gation sur 550 fichiers Parquet
SELECT 
    year,
    COUNT(*) as total_transactions,
    SUM(amount) as total_revenue,
    MIN(amount) as min_sale,
    MAX(amount) as max_sale,
    AVG(amount) as avg_sale
FROM minio_sales."sales-data".sales
GROUP BY year
ORDER BY year DESC;
```

**Action**: Noter le temps d'ex√©cution (g√©n√©ralement < 2 secondes)

**Point cl√©**:
> "Parquet columnar + compression Snappy + query pushdown = performance exceptionnelle."

---

#### D√©mo 3.3: Data Lineage (2 min)

**Narratif**:
> "Dremio trace automatiquement la provenance des donn√©es pour la gouvernance."

**Action**: 
1. Cliquer sur un VDS (ex: `raw.customer_activity`)
2. Onglet **Overview**
3. Section **Lineage** ‚Üí Voir le graphe

**Point cl√©**:
> "Tra√ßabilit√© compl√®te: sources ‚Üí VDS ‚Üí mod√®les dbt ‚Üí dashboards BI."

---

### üé¨ PHASE 4: Pipeline dbt (3 min)

#### D√©mo 4.1: Structure des Mod√®les (1 min)

**Narratif**:
> "dbt orchestre la transformation des donn√©es en couches: staging pour nettoyer, marts pour les KPIs m√©tier."

**Action**: Ouvrir dbt Docs (http://localhost:8080)
- Montrer le graphe de d√©pendances (DAG)
- Cliquer sur `fct_business_overview` (le mod√®le phare)

**Point cl√©**:
> "12 mod√®les, 40 tests de qualit√©, documentation automatique. Gouvernance by design!"

---

#### D√©mo 4.2: Tests de Qualit√© (1 min)

**Narratif**:
> "dbt valide la qualit√© des donn√©es √† chaque ex√©cution avec des tests automatis√©s."

**Action**: Dans dbt Docs
- Cliquer sur `stg_es_logs`
- Onglet **Tests**
- Montrer les tests: `not_null`, `accepted_values`, etc.

**SQL des tests**:
```yaml
# Exemple de tests dans schema.yml
tests:
  - not_null:
      columns: [log_timestamp, service, log_level]
  - accepted_values:
      column: log_level
      values: ['ERROR', 'WARNING', 'INFO', 'DEBUG']
```

**Point cl√©**:
> "13/14 tests passent (92.9%). Anomalies d√©tect√©es automatiquement."

---

#### D√©mo 4.3: Ex√©cution dbt en Live (1 min)

**Narratif**:
> "Ex√©cutons le pipeline complet: staging ‚Üí marts ‚Üí tests."

**Action**: Terminal
```bash
cd c:\projets\dremiodbt\dbt

# Ex√©cuter tous les mod√®les
dbt run

# Tester la qualit√©
dbt test --select stg_es_*
```

**Output attendu**:
```
Completed successfully
Done. PASS=3 WARN=0 ERROR=0 SKIP=0 TOTAL=3

Tests:
PASS: 13 | FAIL: 1 | SKIP: 0 | TOTAL: 14
```

**Point cl√©**:
> "Pipeline versioned (Git), document√© (dbt docs), test√© (dbt test). Production-ready!"

---

### üé¨ PHASE 5: Cas d'Usage Business (3 min)

#### Cas d'Usage 1: Dashboard Executive (1 min 30)

**Narratif**:
> "Le CFO veut une vue consolid√©e du chiffre d'affaires toutes sources confondues. Une seule requ√™te SQL suffit!"

**SQL √† ex√©cuter**:
```sql
-- Vue 360¬∞ combinant PostgreSQL + MinIO + Elasticsearch
SELECT 
    business_date,
    
    -- Revenus combin√©s
    combined_revenue as "CA Total ‚Ç¨",
    pg_revenue as "Ventes Web ‚Ç¨",
    minio_revenue as "Ventes Historiques ‚Ç¨",
    
    -- Activit√©
    pg_transactions as "Commandes",
    web_conversions as "Conversions Web",
    active_users as "Utilisateurs Actifs",
    
    -- Sant√© plateforme
    platform_errors as "Erreurs Syst√®me",
    
    -- KPIs
    ROUND(conversion_rate, 2) as "Taux Conversion %",
    CASE 
        WHEN platform_errors > 10 THEN 'üî¥ CRITIQUE'
        WHEN platform_errors > 5 THEN 'üü° ATTENTION'
        ELSE 'üü¢ OK'
    END as "Statut Plateforme"
    
FROM marts.fct_business_overview
WHERE business_date >= CURRENT_DATE - 30
ORDER BY business_date DESC;
```

**Point cl√©**:
> "3 sources diff√©rentes, 1 seule requ√™te, temps r√©el. C'est √ßa la valeur de Dremio + dbt."

---

#### Cas d'Usage 2: Analyse Pr√©dictive (1 min 30)

**Narratif**:
> "Le Data Scientist veut identifier les clients √† risque de churn. Corr√©lons commandes + √©v√©nements web."

**SQL √† ex√©cuter**:
```sql
-- Clients avec faible engagement r√©cent
WITH customer_metrics AS (
    SELECT 
        customer_id,
        customer_name,
        total_orders,
        total_spent,
        last_order_date,
        days_since_last_order,
        CASE 
            WHEN total_orders >= 5 THEN 'VIP'
            WHEN total_orders >= 3 THEN 'Regular'
            ELSE 'Occasional'
        END as segment
    FROM marts.dim_customers
),
web_activity AS (
    SELECT 
        user_id,
        COUNT(*) as events_last_30d,
        SUM(is_conversion) as conversions_last_30d
    FROM staging.stg_es_events
    WHERE day >= CURRENT_DATE - 30
    GROUP BY user_id
)
SELECT 
    cm.customer_name,
    cm.segment,
    cm.total_orders,
    cm.days_since_last_order,
    COALESCE(wa.events_last_30d, 0) as web_events,
    COALESCE(wa.conversions_last_30d, 0) as conversions,
    CASE 
        WHEN cm.days_since_last_order > 90 AND wa.events_last_30d < 5 THEN 'üö® CHURN RISK'
        WHEN cm.days_since_last_order > 60 THEN '‚ö†Ô∏è AT RISK'
        ELSE '‚úÖ ACTIVE'
    END as churn_prediction
FROM customer_metrics cm
LEFT JOIN web_activity wa ON CAST(cm.customer_id AS VARCHAR) = wa.user_id
WHERE cm.total_orders > 0
ORDER BY cm.days_since_last_order DESC, wa.events_last_30d ASC
LIMIT 20;
```

**Point cl√©**:
> "Corr√©lation multi-sources pour pr√©diction m√©tier. Requ√™te SQL, pas besoin de Python/Spark!"

---

## üéØ Messages Cl√©s √† Retenir

### Pour les D√©cideurs (CxO)

1. **ROI rapide**: Pas d'ETL √† d√©velopper/maintenir = √©conomies substantielles
2. **Time-to-insight r√©duit**: Requ√™tes SQL directes, pas d'attente pipeline
3. **Gouvernance int√©gr√©e**: dbt teste la qualit√©, trace la lineage

### Pour les Data Engineers

1. **No-copy architecture**: Dremio virtualise, pas de duplication
2. **Query pushdown**: Performance native (Parquet, PostgreSQL, ES)
3. **Infrastructure as Code**: Docker + dbt = reproductible, versionn√©

### Pour les Analystes BI

1. **SQL standard**: Pas de syntaxe propri√©taire √† apprendre
2. **Documentation automatique**: dbt docs pour comprendre les mod√®les
3. **Tests de qualit√©**: Confiance dans les donn√©es analys√©es

---

## üîÑ Plan B (Si Probl√®me Technique)

### Probl√®me: Service Docker down

**Action**:
```powershell
docker-compose restart [service_name]
# Attendre 30 secondes
```

**Narratif**:
> "Pendant le red√©marrage, laissez-moi vous montrer le code dbt..."

---

### Probl√®me: Requ√™te lente

**Action**: Passer √† la requ√™te suivante

**Narratif**:
> "Cette requ√™te prend un peu plus de temps sur cette machine, mais en production avec des ressources adapt√©es..."

---

### Probl√®me: VDS non trouv√©

**Action**: Utiliser les sources directes (PostgreSQL, MinIO)

**Narratif**:
> "Les Virtual Datasets sont optionnels, Dremio peut requ√™ter directement les sources..."

---

## üìä M√©triques √† Mentionner

### Pendant la D√©mo

- **2,425+ records** au total sur 3 sources
- **550 fichiers Parquet** dans MinIO
- **12 mod√®les dbt** orchestr√©s
- **92.9% de tests** valid√©s (13/14)
- **< 2 secondes** pour requ√™ter 550 fichiers Parquet

### Gains Mesurables

- **80% de r√©duction** du temps de d√©veloppement ETL (vs. ETL classique)
- **0 copie de donn√©es** = √©conomies stockage + conformit√© RGPD
- **100% SQL standard** = comp√©tences existantes r√©utilisables

---

## üé§ Questions Fr√©quentes (Q&A)

### Q1: "Quelle est la limite de volume de donn√©es?"

**R**: "Dremio est con√ßu pour le Big Data. Cette d√©mo utilise 2,425 records, mais en production nous avons des clients avec des p√©taoctets. Dremio scale horizontalement avec des clusters distribu√©s."

### Q2: "Est-ce compatible avec notre BI actuel (Tableau/Power BI)?"

**R**: "Oui, Dremio expose un endpoint ODBC/JDBC standard. Tableau, Power BI, Looker, tous se connectent nativement. C'est transparent pour les utilisateurs."

### Q3: "Comment g√©rer la s√©curit√© et les permissions?"

**R**: "Dremio int√®gre RBAC (Role-Based Access Control). Vous d√©finissez des r√¥les, attribuez des permissions par source/VDS/colonne. OpenMetadata compl√®te pour la gouvernance."

### Q4: "Quel est le co√ªt de licence Dremio?"

**R**: "Cette d√©mo utilise Dremio OSS (open-source, gratuit). Pour la version Enterprise, contactez Dremio pour un devis personnalis√© selon votre volum√©trie."

### Q5: "Comment se compare Dremio √† Snowflake/Databricks?"

**R**: "Diff√©rent: Snowflake/Databricks sont des data warehouses (copient les donn√©es). Dremio est une couche de virtualisation (z√©ro copie). Compl√©mentaires, pas concurrents. Vous pouvez m√™me virtualiser Snowflake avec Dremio!"

---

## ‚úÖ Checklist Post-D√©mo

- [ ] Partager les slides de pr√©sentation
- [ ] Envoyer le lien GitHub du repository
- [ ] Proposer un atelier hands-on (2 heures)
- [ ] Programmer un call de suivi (1 semaine)
- [ ] Fournir les ressources:
  - Documentation Dremio: https://docs.dremio.com/
  - Documentation dbt: https://docs.getdbt.com/
  - Repository sandbox: [lien GitHub]

---

## üéì Ressources Compl√©mentaires

### Pour Approfondir

- **[ARCHITECTURE.md](ARCHITECTURE.md)** - D√©tails techniques
- **[QUICKSTART.md](QUICKSTART.md)** - Setup pour test local
- **[SANDBOX_IMPROVEMENTS.md](../SANDBOX_IMPROVEMENTS.md)** - Roadmap

### Exemples de Code

- Scripts Python: `c:\projets\dremiodbt\scripts\`
- Mod√®les dbt: `c:\projets\dremiodbt\dbt\models\`
- Tests dbt: `c:\projets\dremiodbt\dbt\models\schema.yml`

---

**Version**: 1.0 | **Dur√©e**: 15 min | **Difficult√©**: ‚≠ê‚≠ê‚≠ê‚òÜ‚òÜ

**üé¨ Bonne d√©monstration!**

---

**Derni√®re mise √† jour**: 14 Octobre 2025

# Airbyte Entegrasyon KÄ±lavuzu

**SÃ¼rÃ¼m**: 3.2.0  
**Son GÃ¼ncelleme**: 16 Ekim 2025  
**Dil**: FransÄ±zca

---

## Genel BakÄ±ÅŸ

Airbyte, verilerin Ã§eÅŸitli kaynaklardan hedeflere taÅŸÄ±nmasÄ±nÄ± kolaylaÅŸtÄ±ran aÃ§Ä±k kaynaklÄ± bir veri entegrasyon platformudur. Bu kÄ±lavuz Airbyte'Ä±n veri platformuna entegre edilmesini, baÄŸlayÄ±cÄ±larÄ±n yapÄ±landÄ±rÄ±lmasÄ±nÄ± ve veri hatlarÄ± oluÅŸturulmasÄ±nÄ± kapsar.

```mermaid
graph LR
    A[Sources de DonnÃ©es] -->|Extraire| B[Airbyte]
    B -->|Transformer| C[Normalisation Airbyte]
    C -->|Charger| D[Destinations]
    D --> E[MinIO S3]
    D --> F[PostgreSQL]
    D --> G[Dremio]
    
    style B fill:#615EFF
    style E fill:#C72E49
    style F fill:#336791
    style G fill:#FDB515
```

---

## Airbyte nedir?

### Temel Ã–zellikler

- **300'den fazla Ã–nceden OluÅŸturulmuÅŸ BaÄŸlayÄ±cÄ±**: API'ler, veritabanlarÄ±, dosyalar, SaaS uygulamalarÄ±
- **AÃ§Ä±k Kaynak**: Tam veri kontrolÃ¼ ile kendi kendine barÄ±ndÄ±rÄ±lan
- **Veri YakalamayÄ± DeÄŸiÅŸtir (CDC)**: GerÃ§ek zamanlÄ± veri senkronizasyonu
- **Ã–zel BaÄŸlayÄ±cÄ±lar**: Python veya dÃ¼ÅŸÃ¼k kodlu CDK ile baÄŸlayÄ±cÄ±lar oluÅŸturun
- **Veri NormalleÅŸtirme**: Ham JSON'u yapÄ±landÄ±rÄ±lmÄ±ÅŸ tablolara dÃ¶nÃ¼ÅŸtÃ¼rÃ¼n
- **Ä°zleme ve UyarÄ±lar**: Senkronizasyon durumunu ve veri kalitesini izleyin

### MimarlÄ±k

```mermaid
graph TB
    subgraph "Plateforme Airbyte"
        W[Interface Web :8000]
        S[Serveur :8001]
        WK[Worker]
        T[Workflow Temporal]
        DB[(BD Airbyte)]
    end
    
    subgraph "Flux de DonnÃ©es"
        SRC[Sources] -->|Extraire| WK
        WK -->|DonnÃ©es Brutes| DEST[Destinations]
        WK -->|Normaliser| DBT[ModÃ¨les dbt]
        DBT --> DEST
    end
    
    W -->|Appels API| S
    S -->|Mettre en File| T
    T -->|ExÃ©cuter| WK
    WK -->|MÃ©tadonnÃ©es| DB
    
    style W fill:#615EFF
    style S fill:#615EFF
    style WK fill:#615EFF
```

---

## Tesis

### HÄ±zlÄ± BaÅŸlangÄ±Ã§

Airbyte platforma dahildir. Åununla baÅŸlayÄ±n:

```bash
# DÃ©marrer services Airbyte
docker-compose -f docker-compose-airbyte.yml up -d

# VÃ©rifier statut
docker-compose -f docker-compose-airbyte.yml ps

# Voir logs
docker-compose -f docker-compose-airbyte.yml logs -f
```

### Hizmetler BaÅŸladÄ±

| Hizmetler | Liman | AÃ§Ä±klama |
|----------|----------|------------|
| **airbyte-webapp** | 8000 | Web kullanÄ±cÄ± arayÃ¼zÃ¼ |
| **airbyte-sunucusu** | 8001 | API Sunucusu |
| **airbyte-iÅŸÃ§isi** | - | Ä°ÅŸ yÃ¼rÃ¼tme motoru |
| **airbyte-zamansal** | 7233 | Ä°ÅŸ akÄ±ÅŸÄ± orkestrasyonu |
| **airbyte-db** | 5432 | Meta veri veritabanÄ± (PostgreSQL) |

### Ä°lk EriÅŸim

**Web ArayÃ¼zÃ¼:**
```
http://localhost:8000
```

**VarsayÄ±lan tanÄ±mlayÄ±cÄ±lar:**
- **E-posta**: `airbyte@example.com`
- **Åifre**: `password`

GÃ¼venlik amacÄ±yla ilk kez oturum aÃ§arken **ÅŸifreyi deÄŸiÅŸtirin**.

---

## YapÄ±landÄ±rma

### YapÄ±landÄ±rma SihirbazÄ±

Ä°lk eriÅŸimde yapÄ±landÄ±rma sihirbazÄ±nÄ± tamamlayÄ±n:

1. **E-posta Tercihleri**: Bildirimleri yapÄ±landÄ±rÄ±n
2. **Veri YerleÅŸimi**: Veri depolama konumunu seÃ§in
3. **Anonim KullanÄ±m Ä°statistikleri**: Telemetriyi kabul et/reddet

### Ã‡alÄ±ÅŸma alanÄ± ayarlarÄ±

**Ayarlar > Ã‡alÄ±ÅŸma AlanÄ±**'na gidin:

```yaml
Nom Workspace: Production Data Platform
ID Workspace: default
DÃ©finition Namespace: Destination Default
Format Namespace: ${SOURCE_NAMESPACE}
```

### Kaynak SÄ±nÄ±rlarÄ±

**Dosya**: `config/airbyte/config.yaml`

```yaml
# Allocation ressources par connecteur
resources:
  source:
    cpu_limit: "1.0"
    memory_limit: "1Gi"
    cpu_request: "0.25"
    memory_request: "256Mi"
  
  destination:
    cpu_limit: "1.0"
    memory_limit: "1Gi"
    cpu_request: "0.25"
    memory_request: "256Mi"
  
  orchestrator:
    cpu_limit: "0.5"
    memory_limit: "512Mi"
```

---

## KonektÃ¶rler

### Kaynak BaÄŸlayÄ±cÄ±larÄ±

#### Kaynak PostgreSQL

**KullanÄ±m Ã–rneÄŸi**: Ä°ÅŸlemsel veritabanÄ±ndan veri Ã§Ä±karma

**YapÄ±landÄ±rma:**

1. **Kaynaklar > Yeni Kaynak**'a gidin
2. **PostgreSQL**'i seÃ§in
3. BaÄŸlantÄ±yÄ± yapÄ±landÄ±rÄ±n:

```yaml
Host: postgres
Port: 5432
Database: source_db
Username: readonly_user
Password: [MOT_DE_PASSE_SÃ‰CURISÃ‰]
SSL Mode: prefer

MÃ©thode RÃ©plication: Standard
  # Ou CDC pour changements temps rÃ©el:
  # MÃ©thode RÃ©plication: Logical Replication (CDC)
```

**BaÄŸlantÄ±yÄ± Test Et** â†’ **KaynaÄŸÄ± ayarla**

#### REST API kaynaÄŸÄ±

**KullanÄ±m Ã–rneÄŸi**: API'lerden veri ayÄ±klama

**YapÄ±landÄ±rma:**

```yaml
Name: External API
URL Base: https://api.example.com/v1
Authentication:
  Type: Bearer Token
  Token: [API_TOKEN]

Endpoints:
  - name: customers
    path: /customers
    http_method: GET
    
  - name: orders
    path: /orders
    http_method: GET
    params:
      start_date: "{{ config['start_date'] }}"
```

#### Kaynak DosyasÄ± (CSV)

**KullanÄ±m Ã–rneÄŸi**: CSV dosyalarÄ±nÄ± iÃ§e aktarÄ±n

**YapÄ±landÄ±rma:**

```yaml
Dataset Name: sales_data
URL: https://storage.example.com/sales.csv
Format: CSV
Provider:
  Storage: HTTPS
  User Provided Storage:
    URL: https://storage.example.com/sales.csv
```

#### Ortak Kaynaklar

| Kaynak | KullanÄ±m DurumlarÄ± | CDC DesteÄŸi |
|-----------|-----------|-------------|
| **PostgreSQL** | Ä°ÅŸlemsel Ã§izgi romanlar | âœ… Evet |
| **MySQL** | Ä°ÅŸlemsel Ã§izgi romanlar | âœ… Evet |
| **MongoDB** | NoSQL Belgeleri | âœ… Evet |
| **SatÄ±ÅŸ gÃ¼cÃ¼** | CRM verileri | âŒ HayÄ±r |
| **Google E-Tablolar** | Elektronik Tablolar | âŒ HayÄ±r |
| **Åerit** | Ã–deme verileri | âŒ HayÄ±r |
| **REST API** | Ã–zel API'ler | âŒ HayÄ±r |
| **S3** | Dosya depolama | âŒ HayÄ±r |

### Hedef KonektÃ¶rleri

#### MinIO S3 Hedefi

**KullanÄ±m Ã–rneÄŸi**: Ham verileri veri gÃ¶lÃ¼nde depolayÄ±n

**YapÄ±landÄ±rma:**

1. **Hedefler > Yeni Hedef**'e gidin
2. **S3**'Ã¼ seÃ§in
3. BaÄŸlantÄ±yÄ± yapÄ±landÄ±rÄ±n:

```yaml
S3 Bucket Name: datalake
S3 Bucket Path: airbyte-data/${NAMESPACE}/${STREAM_NAME}
S3 Bucket Region: us-east-1

# Point de terminaison MinIO
S3 Endpoint: http://minio:9000
Access Key ID: [MINIO_ROOT_USER]
Secret Access Key: [MINIO_ROOT_PASSWORD]

Output Format:
  Format Type: Parquet
  Compression: GZIP
  Block Size: 128MB
```

**BaÄŸlantÄ±yÄ± Test Et** â†’ **Hedefi ayarlayÄ±n**

#### PostgreSQL hedefi

**KullanÄ±m Ã–rneÄŸi**: Analiz iÃ§in dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lmÃ¼ÅŸ verileri yÃ¼kleyin

**YapÄ±landÄ±rma:**

```yaml
Host: postgres
Port: 5432
Database: analytics_db
Username: analytics_user
Password: [MOT_DE_PASSE_SÃ‰CURISÃ‰]
Default Schema: public

Normalization:
  Mode: Basic
  # CrÃ©e tables normalisÃ©es depuis JSON imbriquÃ©
```

#### Hedef Dremio

**KullanÄ±m Ã–rneÄŸi**: Veri gÃ¶l evine doÄŸrudan yÃ¼kleme

**YapÄ±landÄ±rma:**

```yaml
Host: dremio
Port: 32010
Project: Production
Dataset: airbyte_data
Username: dremio_user
Password: [DREMIO_PASSWORD]

Connection Type: Arrow Flight
SSL: false
```

---

## BaÄŸlantÄ±lar

### BaÄŸlantÄ± OluÅŸtur

BaÄŸlantÄ±, bir kaynaÄŸÄ± bir hedefe baÄŸlar.

```mermaid
sequenceDiagram
    participant S as Source
    participant A as Airbyte
    participant D as Destination
    
    S->>A: 1. Extraire donnÃ©es
    A->>A: 2. Appliquer transformations
    A->>D: 3. Charger donnÃ©es
    D->>D: 4. Normaliser (optionnel)
    A->>A: 5. Mettre Ã  jour Ã©tat
    
    Note over A: Sync terminÃ©e
```

#### AdÄ±m AdÄ±m

1. **BaÄŸlantÄ±lar > Yeni BaÄŸlantÄ±'ya gidin**

2. **Kaynak SeÃ§in**: YapÄ±landÄ±rÄ±lmÄ±ÅŸ kaynaÄŸÄ± seÃ§in (Ã¶r. PostgreSQL)

3. **Hedef SeÃ§in**: Hedef seÃ§in (Ã¶r. MinIO S3)

4. **Senkronizasyonu YapÄ±landÄ±rÄ±n**:

```yaml
Nom Connexion: PostgreSQL â†’ MinIO
FrÃ©quence RÃ©plication: Every 24 hours
Namespace Destination: Custom
  Format Namespace: production_${SOURCE_NAMESPACE}

Streams:
  - customers
    Mode Sync: Full Refresh | Overwrite
    Champ Curseur: updated_at
    ClÃ© Primaire: customer_id
    
  - orders
    Mode Sync: Incremental | Append
    Champ Curseur: created_at
    ClÃ© Primaire: order_id
    
  - products
    Mode Sync: Full Refresh | Overwrite
    ClÃ© Primaire: product_id
```

5. **NormalleÅŸtirmeyi YapÄ±landÄ±rÄ±n** (isteÄŸe baÄŸlÄ±):

```yaml
Normalization:
  Enable: true
  Option: Basic Normalization
  # Convertit JSON imbriquÃ© en tables plates
```

6. **BaÄŸlantÄ±yÄ± Test Et** â†’ **BaÄŸlantÄ±yÄ± kurun**

### Senkronizasyon ModlarÄ±

| Moda | AÃ§Ä±klama | KullanÄ±m DurumlarÄ± |
|------|-------------|------------|
| **Tam Yenileme\| Ãœzerine Yaz** | TÃ¼m verileri deÄŸiÅŸtir | Boyut tablolarÄ± |
| **Tam Yenileme\| Ekle** | TÃ¼m kayÄ±tlarÄ± ekle | GeÃ§miÅŸ izleme |
| **ArtÄ±mlÄ±\| Ekle** | Yeni/gÃ¼ncellenmiÅŸ kayÄ±tlar ekle | GerÃ§ek tablolarÄ± |
| **ArtÄ±mlÄ±\| TekilleÅŸtirildi** | Mevcut kayÄ±tlarÄ± gÃ¼ncelle | SCD Tip 1 |

### Planlama

**Frekans SeÃ§enekleri:**
- **Manuel**: Manuel olarak tetikleyin
- **Saatlik**: Her saat
- **GÃ¼nlÃ¼k**: Her 24 saatte bir (saati belirtin)
- **HaftalÄ±k**: HaftanÄ±n belirli gÃ¼nleri
- **Cron**: Ã–zel planlama (Ã¶r. `0 2 * * *`)

**Ã‡izelge Ã¶rnekleri:**
```yaml
# Toutes les 6 heures
Cron: 0 */6 * * *

# Jours de semaine Ã  2h du matin
Cron: 0 2 * * 1-5

# Premier jour du mois
Cron: 0 0 1 * *
```

---

## Veri DÃ¶nÃ¼ÅŸÃ¼mÃ¼

### Temel NormalleÅŸtirme

Airbyte, dbt'yi kullanan **Temel NormalleÅŸtirme**'yi iÃ§erir:

**Ne yapar:**
- YuvalanmÄ±ÅŸ JSON'u dÃ¼z tablolara dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r
- Tablolar oluÅŸturun `_airbyte_raw_*` (ham JSON)
- StandartlaÅŸtÄ±rÄ±lmÄ±ÅŸ (yapÄ±landÄ±rÄ±lmÄ±ÅŸ) tablolar oluÅŸturur
- Meta veri sÃ¼tunlarÄ± ekleyin (`_airbyte_emitted_at`, `_airbyte_normalized_at`)

**Ã–rnek:**

**Ham JSON** (`_airbyte_raw_customers`):
```json
{
  "_airbyte_ab_id": "uuid-123",
  "_airbyte_emitted_at": "2025-10-16T10:00:00Z",
  "_airbyte_data": {
    "id": 1,
    "name": "Acme Corp",
    "contact": {
      "email": "info@acme.com",
      "phone": "+1234567890"
    },
    "addresses": [
      {"type": "billing", "city": "New York"},
      {"type": "shipping", "city": "Boston"}
    ]
  }
}
```

**Standart Tablolar:**

`customers`:
```sql
id | name | contact_email | contact_phone | _airbyte_normalized_at
1 | Acme Corp | info@acme.com | +1234567890 | 2025-10-16 10:05:00
```

`customers_addresses`:
```sql
_airbyte_customers_hashid | type | city
hash-123 | billing | New York
hash-123 | shipping | Boston
```

### Ã–zel DÃ¶nÃ¼ÅŸÃ¼mler (dbt)

GeliÅŸmiÅŸ dÃ¶nÃ¼ÅŸÃ¼mler iÃ§in dbt'yi kullanÄ±n:

1. **Airbyte NormalleÅŸtirmeyi Devre DÄ±ÅŸÄ± BÄ±rakÄ±n**
2. Tablolara referans vererek **dbt modelleri oluÅŸturun** `_airbyte_raw_*`
3. **Airbyte senkronizasyonundan sonra dbt'yi Ã§alÄ±ÅŸtÄ±rÄ±n**

**Dbt modeli Ã¶rneÄŸi:**
```sql
-- models/staging/stg_customers.sql
with source as (
    select * from {{ source('airbyte_raw', '_airbyte_raw_customers') }}
),

parsed as (
    select
        _airbyte_ab_id,
        _airbyte_emitted_at,
        (_airbyte_data->>'id')::int as customer_id,
        _airbyte_data->>'name' as customer_name,
        _airbyte_data->'contact'->>'email' as email,
        _airbyte_data->'contact'->>'phone' as phone
    from source
)

select * from parsed
```

---

## Ä°zleme

### Senkronizasyon Durumu

**Kontrol Paneli Web ArayÃ¼zÃ¼:**
- **BaÄŸlantÄ±lar**: TÃ¼m baÄŸlantÄ±larÄ± gÃ¶rÃ¼n
- **Senkronizasyon GeÃ§miÅŸi**: GeÃ§miÅŸ senkronizasyon iÅŸleri
- **GÃ¼nlÃ¼kleri EÅŸitle**: Ä°ÅŸ baÅŸÄ±na ayrÄ±ntÄ±lÄ± gÃ¼nlÃ¼kler

**Durum GÃ¶stergeleri:**
- ğŸŸ¢ **BaÅŸarÄ±lÄ±**: Senkronizasyon baÅŸarÄ±yla tamamlandÄ±
- ğŸ”´ **BaÅŸarÄ±sÄ±z**: Senkronizasyon baÅŸarÄ±sÄ±z oldu (gÃ¼nlÃ¼kleri kontrol et)
- ğŸŸ¡ **Ã‡alÄ±ÅŸÄ±yor**: Senkronizasyon devam ediyor
- âšª **Ä°ptal edildi**: Senkronizasyon kullanÄ±cÄ± tarafÄ±ndan iptal edildi

### GÃ¼nlÃ¼kler

**Senkronizasyon gÃ¼nlÃ¼klerine bakÄ±n:**
```bash
# Logs serveur Airbyte
docker-compose -f docker-compose-airbyte.yml logs airbyte-server

# Logs worker (exÃ©cution sync rÃ©elle)
docker-compose -f docker-compose-airbyte.yml logs airbyte-worker

# Logs job spÃ©cifique
# Disponible dans Interface Web: Connections > [Connection] > Job History > [Job]
```

### Metrikler

**Ä°zlenecek Temel Metrikler:**
- **Senkronize KayÄ±tlar**: Senkronizasyon baÅŸÄ±na kayÄ±t sayÄ±sÄ±
- **Senkronize Bayt**: AktarÄ±lan veri hacmi
- **Senkronizasyon SÃ¼resi**: Senkronizasyon baÅŸÄ±na geÃ§en sÃ¼re
- **BaÅŸarÄ±sÄ±zlÄ±k OranÄ±**: BaÅŸarÄ±sÄ±z senkronizasyonlarÄ±n yÃ¼zdesi

**DÄ±ÅŸa Aktarma Metrikleri:**
```bash
# API Airbyte
curl -X GET "http://localhost:8001/api/v1/jobs/list" \
  -H "Content-Type: application/json" \
  -d '{
    "configTypes": ["sync"],
    "configId": "connection-id"
  }'
```

### UyarÄ±lar

**Ayarlar > Bildirimler** bÃ¶lÃ¼mÃ¼nde **uyarÄ±larÄ± yapÄ±landÄ±rÄ±n**:

```yaml
Type Notification: Slack
URL Webhook: https://hooks.slack.com/services/VOTRE/WEBHOOK/URL

Ã‰vÃ©nements:
  - Ã‰chec Sync
  - SuccÃ¨s Sync (optionnel)
  - Connexion DÃ©sactivÃ©e

Conditions:
  - Seuil Ã©chec: 3 Ã©checs consÃ©cutifs
```

---

## API kullanÄ±mÄ±

### Kimlik DoÄŸrulamasÄ±

```bash
# Pas d'authentification requise pour localhost
# Pour production, configurez auth dans docker-compose-airbyte.yml
```

### Ortak API Ã‡aÄŸrÄ±larÄ±

#### KaynaklarÄ± Listele

```bash
curl -X POST "http://localhost:8001/api/v1/sources/list" \
  -H "Content-Type: application/json" \
  -d '{
    "workspaceId": "workspace-id"
  }'
```

#### BaÄŸlantÄ± OluÅŸtur

```bash
curl -X POST "http://localhost:8001/api/v1/connections/create" \
  -H "Content-Type: application/json" \
  -d '{
    "sourceId": "source-id",
    "destinationId": "destination-id",
    "syncCatalog": {
      "streams": [
        {
          "stream": {
            "name": "customers",
            "jsonSchema": {...}
          },
          "config": {
            "syncMode": "incremental",
            "destinationSyncMode": "append",
            "cursorField": ["updated_at"]
          }
        }
      ]
    },
    "schedule": {
      "units": 24,
      "timeUnit": "hours"
    }
  }'
```

#### Senkronizasyonu Tetikle

```bash
curl -X POST "http://localhost:8001/api/v1/connections/sync" \
  -H "Content-Type: application/json" \
  -d '{
    "connectionId": "connection-id"
  }'
```

#### Ä°ÅŸ Durumunu Al

```bash
curl -X POST "http://localhost:8001/api/v1/jobs/get" \
  -H "Content-Type: application/json" \
  -d '{
    "id": "job-id"
  }'
```

---

## Dremio ile entegrasyon

### Ä°ÅŸ AkÄ±ÅŸÄ±

```mermaid
sequenceDiagram
    participant Src as Source DonnÃ©es
    participant Ab as Airbyte
    participant S3 as MinIO S3
    participant Dr as Dremio
    participant Dbt as dbt
    
    Src->>Ab: 1. Extraire donnÃ©es
    Ab->>S3: 2. Charger vers S3 (Parquet)
    S3->>Dr: 3. Dremio lit S3
    Dr->>Dbt: 4. dbt transforme
    Dbt->>Dr: 5. Ã‰crire rÃ©sultats
    Dr->>Dr: 6. Couche requÃªte prÃªte
```

### YapÄ±landÄ±rma AdÄ±mlarÄ±

1. **Airbyte'Ä± MinIO S3'Ã¼ ÅŸarj edecek ÅŸekilde yapÄ±landÄ±rÄ±n** (yukarÄ±ya bakÄ±n)

2. **Dremio'ya S3 kaynaÄŸÄ±nÄ± ekleyin:**

```sql
-- Dans Interface Dremio: Sources > Add Source > S3
Nom Source: AirbyteData
Authentication: AWS Access Key
ClÃ© AccÃ¨s: [MINIO_ROOT_USER]
ClÃ© SecrÃ¨te: [MINIO_ROOT_PASSWORD]
Chemin Racine: /
PropriÃ©tÃ©s Connexion:
  fs.s3a.endpoint: minio:9000
  fs.s3a.path.style.access: true
  dremio.s3.compat: true
```

3. **Dremio'da Airbyte verilerini sorgulayÄ±n:**

```sql
-- Parcourir structure S3
SELECT * FROM AirbyteData.datalake."airbyte-data"

-- RequÃªte table spÃ©cifique
SELECT *
FROM AirbyteData.datalake."airbyte-data".production_public.customers
LIMIT 100
```

4. **Dremio Sanal Veri KÃ¼mesini OluÅŸturun:**

```sql
CREATE VDS airbyte_customers AS
SELECT
  id as customer_id,
  name as customer_name,
  contact_email as email,
  contact_phone as phone,
  _airbyte_emitted_at as last_updated
FROM AirbyteData.datalake."airbyte-data".production_public.customers
```

5. **dbt modellerinde kullanÄ±n:**

```yaml
# dbt/models/sources.yml
sources:
  - name: airbyte
    schema: AirbyteData.datalake."airbyte-data".production_public
    tables:
      - name: customers
      - name: orders
      - name: products
```

---

## En Ä°yi Uygulamalar

### Performans

1. **MÃ¼mkÃ¼n olduÄŸunda ArtÄ±mlÄ± SenkronizasyonlarÄ± kullanÄ±n**
2. **SenkronizasyonlarÄ± yoÄŸun olmayan saatlere planlayÄ±n**
3. **Daha iyi sÄ±kÄ±ÅŸtÄ±rma iÃ§in Parke formatÄ±nÄ± kullanÄ±n**
4. **BÃ¼yÃ¼k tablolarÄ± tarihe gÃ¶re bÃ¶lÃ¼mleyin**
5. **Kaynak kullanÄ±mÄ±nÄ± izleyin** ve sÄ±nÄ±rlarÄ± ayarlayÄ±n

### Veri Kalitesi

1. Kaynak baÄŸlayÄ±cÄ±larda **veri doÄŸrulamayÄ± etkinleÅŸtirin**
2. KopyalarÄ± tespit etmek iÃ§in **birincil anahtarlarÄ± kullanÄ±n**
3. Senkronizasyon hatalarÄ± iÃ§in **uyarÄ±larÄ± yapÄ±landÄ±rÄ±n**
4. **Veri gÃ¼ncelliÄŸini izleyin** metrikleri
5. Ham veriler Ã¼zerinde **dbt testlerini uygulayÄ±n**

### GÃ¼venlik

1. **Kaynaklar iÃ§in salt okunur tanÄ±mlayÄ±cÄ±larÄ± kullanÄ±n**
2. **SÄ±rlarÄ± ortam deÄŸiÅŸkenlerinde saklayÄ±n**
3. **BaÄŸlantÄ±lar iÃ§in SSL/TLS'yi etkinleÅŸtirin**
4. **TanÄ±mlayÄ±cÄ±larÄ±nÄ±zÄ± dÃ¼zenli olarak yenileyin**
5. **EriÅŸim gÃ¼nlÃ¼klerini dÃ¼zenli aralÄ±klarla denetleyin**

### Maliyet Optimizasyonu

1. **SÄ±kÄ±ÅŸtÄ±rma kullanÄ±n** (GZIP, SNAPPY)
2. **Verileri tekilleÅŸtirme** kaynakta
3. **Eski verileri arÅŸivleyin** soÄŸuk depolamaya
4. **Senkronizasyon sÄ±klÄ±ÄŸÄ±nÄ± izleyin** ve gereksinimler
5. **BaÅŸarÄ±sÄ±z senkronizasyon verilerini temizleyin**

---

## Sorun Giderme

### YaygÄ±n Sorunlar

#### Senkronizasyon HatasÄ±: BaÄŸlantÄ± Zaman AÅŸÄ±mÄ±

**Belirti:**
```
Failed to connect to source: Connection timeout
```

**Ã‡Ã¶zÃ¼m:**
```bash
# VÃ©rifier connectivitÃ© rÃ©seau
docker exec airbyte-worker ping postgres

# VÃ©rifier rÃ¨gles pare-feu
# VÃ©rifier hÃ´te/port source dans configuration
```

#### Bellek Yetersiz HatasÄ±

**Belirti:**
```
OOMKilled: Container exceeded memory limit
```

**Ã‡Ã¶zÃ¼m:**
```yaml
# Augmenter limites mÃ©moire dans docker-compose-airbyte.yml
services:
  airbyte-worker:
    environment:
      - JOB_MAIN_CONTAINER_MEMORY_LIMIT=2Gi
      - JOB_MAIN_CONTAINER_MEMORY_REQUEST=1Gi
```

#### NormalleÅŸtirme BaÅŸarÄ±sÄ±z

**Belirti:**
```
Normalization failed: dbt compilation error
```

**Ã‡Ã¶zÃ¼m:**
```bash
# VÃ©rifier logs dbt
docker-compose -f docker-compose-airbyte.yml logs airbyte-worker | grep dbt

# DÃ©sactiver normalisation et utiliser dbt personnalisÃ©
# Meilleur contrÃ´le sur logique transformation
```

#### YavaÅŸ Senkronizasyon PerformansÄ±

**TeÅŸhis:**
```bash
# VÃ©rifier logs sync pour goulot d'Ã©tranglement
# Causes courantes:
# - Grand volume donnÃ©es
# - RequÃªte source lente
# - Latence rÃ©seau
# - Ressources insuffisantes
```

**Ã‡Ã¶zÃ¼mler:**
- Artan senkronizasyon sÄ±klÄ±ÄŸÄ±nÄ± artÄ±rÄ±n
- Ä°mleÃ§ alanlarÄ±na dizin ekle
- GerÃ§ek zamanlÄ± kaynaklar iÃ§in CDC'yi kullanÄ±n
- Ã‡alÄ±ÅŸan kaynaklarÄ±nÄ± Ã¶lÃ§eklendirin

---

## Ä°leri Konular

### Ã–zel BaÄŸlayÄ±cÄ±lar

Airbyte CDK ile Ã¶zel baÄŸlayÄ±cÄ±lar oluÅŸturun:

```bash
# Cloner modÃ¨le connecteur
git clone https://github.com/airbytehq/airbyte.git
cd airbyte/airbyte-integrations/connector-templates/python

# CrÃ©er nouveau connecteur
./create_connector.sh MyCustomAPI

# ImplÃ©menter logique connecteur
# Ã‰diter source.py, spec.yaml, schemas/

# Tester localement
python main.py check --config secrets/config.json
python main.py discover --config secrets/config.json
python main.py read --config secrets/config.json --catalog integration_tests/configured_catalog.json
```

### API DÃ¼zenlemesi

Airbyte'Ä± Python ile otomatikleÅŸtirin:

```python
import requests

AIRBYTE_API = "http://localhost:8001/api/v1"

def trigger_sync(connection_id: str):
    """DÃ©clencher sync manuelle pour connexion"""
    response = requests.post(
        f"{AIRBYTE_API}/connections/sync",
        json={"connectionId": connection_id}
    )
    return response.json()

def get_sync_status(job_id: str):
    """VÃ©rifier statut job sync"""
    response = requests.post(
        f"{AIRBYTE_API}/jobs/get",
        json={"id": job_id}
    )
    return response.json()

# Utilisation
job = trigger_sync("my-connection-id")
status = get_sync_status(job["job"]["id"])
print(f"Statut sync: {status['job']['status']}")
```

---

## Kaynaklar

### Belgeler

- **Airbyte DokÃ¼manlarÄ±**: https://docs.airbyte.com
- **KonektÃ¶r KataloÄŸu**: https://docs.airbyte.com/integrations
- **API ReferansÄ±**: https://airbyte-public-api-docs.s3.us-east-2.amazonaws.com/rapidoc-api-docs.html

### Toplum

- **Slack**: https://slack.airbyte.io
- **GitHub**: https://github.com/airbytehq/airbyte
- **Forum**: https://discuss.airbyte.io

---

## Sonraki AdÄ±mlar

Airbyte'Ä± yapÄ±landÄ±rdÄ±ktan sonra:

1. **Dremio'yu Kurun** - [Dremio Kurulum KÄ±lavuzu](dremio-setup.md)
2. **dbt Modelleri OluÅŸturun** - [dbt GeliÅŸtirme KÄ±lavuzu](dbt-development.md)
3. **Kontrol Panelleri OluÅŸturun** - [SÃ¼perset Kontrol Panelleri KÄ±lavuzu](superset-dashboards.md)
4. **MonitÃ¶r Kalitesi** - [Veri Kalitesi KÄ±lavuzu](data-quality.md)

---

**Airbyte Entegrasyon KÄ±lavuzu SÃ¼rÃ¼mÃ¼**: 3.2.0  
**Son GÃ¼ncelleme**: 16 Ekim 2025  
**BakÄ±mÄ±nÄ± Yapan**: Veri Platformu Ekibi
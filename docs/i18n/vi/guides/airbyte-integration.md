# H∆∞·ªõng d·∫´n t√≠ch h·ª£p Airbyte

**Phi√™n b·∫£n**: 3.2.0  
**C·∫≠p nh·∫≠t l·∫ßn cu·ªëi**: Ng√†y 16 th√°ng 10 nƒÉm 2025  
**Ng√¥n ng·ªØ**: Ti·∫øng Ph√°p

---

## T·ªïng quan

Airbyte l√† m·ªôt n·ªÅn t·∫£ng t√≠ch h·ª£p d·ªØ li·ªáu ngu·ªìn m·ªü gi√∫p ƒë∆°n gi·∫£n h√≥a vi·ªác di chuy·ªÉn d·ªØ li·ªáu t·ª´ nhi·ªÅu ngu·ªìn kh√°c nhau ƒë·∫øn ƒë√≠ch. H∆∞·ªõng d·∫´n n√†y ƒë·ªÅ c·∫≠p ƒë·∫øn vi·ªác t√≠ch h·ª£p Airbyte v√†o n·ªÅn t·∫£ng d·ªØ li·ªáu, ƒë·ªãnh c·∫•u h√¨nh tr√¨nh k·∫øt n·ªëi v√† thi·∫øt l·∫≠p ƒë∆∞·ªùng d·∫´n d·ªØ li·ªáu.

```mermaid
graph LR
    A[Sources de Donn√©es] -->|Extraire| B[Airbyte]
    B -->|Transformer| C[Normalisation Airbyte]
    C -->|Charger| D[Destinations]
    D --> E[MinIO S3]
    D --> F[PostgreSQL]
    D --> G[Dremio]
    
    style B fill:#615EFF
    style E fill:#C72E49
    style F fill:#336791
    style G fill:#FDB515
```

---

##Airbyte l√† g√¨?

### C√°c t√≠nh nƒÉng ch√≠nh

- **300+ Tr√¨nh k·∫øt n·ªëi d·ª±ng s·∫µn**: API, c∆° s·ªü d·ªØ li·ªáu, t·ªáp, ·ª©ng d·ª•ng SaaS
- **Ngu·ªìn m·ªü**: T·ª± l∆∞u tr·ªØ v·ªõi to√†n quy·ªÅn ki·ªÉm so√°t d·ªØ li·ªáu
- **Thu th·∫≠p d·ªØ li·ªáu thay ƒë·ªïi (CDC)**: ƒê·ªìng b·ªô h√≥a d·ªØ li·ªáu theo th·ªùi gian th·ª±c
- **Tr√¨nh k·∫øt n·ªëi t√πy ch·ªânh**: X√¢y d·ª±ng tr√¨nh k·∫øt n·ªëi b·∫±ng Python ho·∫∑c CDK m√£ th·∫•p
- **Chu·∫©n h√≥a d·ªØ li·ªáu**: Chuy·ªÉn ƒë·ªïi JSON th√¥ th√†nh c√°c b·∫£ng c√≥ c·∫•u tr√∫c
- **Gi√°m s√°t & C·∫£nh b√°o**: Theo d√µi tr·∫°ng th√°i ƒë·ªìng b·ªô h√≥a v√† ch·∫•t l∆∞·ª£ng d·ªØ li·ªáu

### Ng√†nh ki·∫øn ‚Äã‚Äã‚Äã‚Äãtr√∫c

```mermaid
graph TB
    subgraph "Plateforme Airbyte"
        W[Interface Web :8000]
        S[Serveur :8001]
        WK[Worker]
        T[Workflow Temporal]
        DB[(BD Airbyte)]
    end
    
    subgraph "Flux de Donn√©es"
        SRC[Sources] -->|Extraire| WK
        WK -->|Donn√©es Brutes| DEST[Destinations]
        WK -->|Normaliser| DBT[Mod√®les dbt]
        DBT --> DEST
    end
    
    W -->|Appels API| S
    S -->|Mettre en File| T
    T -->|Ex√©cuter| WK
    WK -->|M√©tadonn√©es| DB
    
    style W fill:#615EFF
    style S fill:#615EFF
    style WK fill:#615EFF
```

---

## C∆° s·ªü

### B·∫Øt ƒë·∫ßu nhanh

Airbyte ƒë∆∞·ª£c bao g·ªìm trong n·ªÅn t·∫£ng. B·∫Øt ƒë·∫ßu n√≥ v·ªõi:

```bash
# D√©marrer services Airbyte
docker-compose -f docker-compose-airbyte.yml up -d

# V√©rifier statut
docker-compose -f docker-compose-airbyte.yml ps

# Voir logs
docker-compose -f docker-compose-airbyte.yml logs -f
```

### D·ªãch v·ª• ƒë√£ b·∫Øt ƒë·∫ßu

| D·ªãch v·ª• | C·∫£ng | M√¥ t·∫£ |
|--------|------|-------------|
| **airbyte-webapp** | 8000 | Giao di·ªán ng∆∞·ªùi d√πng web |
| **m√°y ch·ªß airbyte** | 8001 | M√°y ch·ªß API |
| **nh√¢n vi√™n airbyte** | - | C√¥ng c·ª• th·ª±c hi·ªán c√¥ng vi·ªác |
| **airbyte-th·ªùi gian** | 7233 | ƒêi·ªÅu ph·ªëi quy tr√¨nh l√†m vi·ªác |
| **airbyte-db** | 5432 | C∆° s·ªü d·ªØ li·ªáu si√™u d·ªØ li·ªáu (PostgreSQL) |

### Truy c·∫≠p l·∫ßn ƒë·∫ßu

**Giao di·ªán web:**
```
http://localhost:8000
```

**S·ªë nh·∫≠n d·∫°ng m·∫∑c ƒë·ªãnh:**
- **Email**: `airbyte@example.com`
- **M·∫≠t kh·∫©u**: `password`

**ƒê·ªïi m·∫≠t kh·∫©u** khi ƒëƒÉng nh·∫≠p l·∫ßn ƒë·∫ßu ƒë·ªÉ b·∫£o m·∫≠t.

---

## C·∫•u h√¨nh

### Tr√¨nh h∆∞·ªõng d·∫´n c·∫•u h√¨nh

Trong l·∫ßn truy c·∫≠p ƒë·∫ßu ti√™n, h√£y ho√†n th√†nh tr√¨nh h∆∞·ªõng d·∫´n c·∫•u h√¨nh:

1. **T√πy ch·ªçn email**: ƒê·ªãnh c·∫•u h√¨nh th√¥ng b√°o
2. **N∆°i l∆∞u tr·ªØ d·ªØ li·ªáu**: Ch·ªçn v·ªã tr√≠ l∆∞u tr·ªØ d·ªØ li·ªáu
3. **Th·ªëng k√™ s·ª≠ d·ª•ng ·∫©n danh**: Ch·∫•p nh·∫≠n/t·ª´ ch·ªëi ƒëo t·ª´ xa

### C√†i ƒë·∫∑t kh√¥ng gian l√†m vi·ªác

ƒêi·ªÅu h∆∞·ªõng t·ªõi **C√†i ƒë·∫∑t > Kh√¥ng gian l√†m vi·ªác**:

```yaml
Nom Workspace: Production Data Platform
ID Workspace: default
D√©finition Namespace: Destination Default
Format Namespace: ${SOURCE_NAMESPACE}
```

### Gi·ªõi h·∫°n t√†i nguy√™n

**T·ªáp**: `config/airbyte/config.yaml`

```yaml
# Allocation ressources par connecteur
resources:
  source:
    cpu_limit: "1.0"
    memory_limit: "1Gi"
    cpu_request: "0.25"
    memory_request: "256Mi"
  
  destination:
    cpu_limit: "1.0"
    memory_limit: "1Gi"
    cpu_request: "0.25"
    memory_request: "256Mi"
  
  orchestrator:
    cpu_limit: "0.5"
    memory_limit: "512Mi"
```

---

## Tr√¨nh k·∫øt n·ªëi

### Tr√¨nh k·∫øt n·ªëi ngu·ªìn

#### Ngu·ªìn PostgreSQL

**Ca s·ª≠ d·ª•ng**: Tr√≠ch xu·∫•t d·ªØ li·ªáu t·ª´ c∆° s·ªü d·ªØ li·ªáu giao d·ªãch

**C·∫•u h√¨nh:**

1. ƒêi·ªÅu h∆∞·ªõng ƒë·∫øn **Ngu·ªìn > Ngu·ªìn m·ªõi**
2. Ch·ªçn **PostgreSQL**
3. C·∫•u h√¨nh k·∫øt n·ªëi:

```yaml
Host: postgres
Port: 5432
Database: source_db
Username: readonly_user
Password: [MOT_DE_PASSE_S√âCURIS√â]
SSL Mode: prefer

M√©thode R√©plication: Standard
  # Ou CDC pour changements temps r√©el:
  # M√©thode R√©plication: Logical Replication (CDC)
```

**Ki·ªÉm tra k·∫øt n·ªëi** ‚Üí **Thi·∫øt l·∫≠p ngu·ªìn**

#### Ngu·ªìn API REST

**Tr∆∞·ªùng h·ª£p s·ª≠ d·ª•ng**: Tr√≠ch xu·∫•t d·ªØ li·ªáu t·ª´ API

**C·∫•u h√¨nh:**

```yaml
Name: External API
URL Base: https://api.example.com/v1
Authentication:
  Type: Bearer Token
  Token: [API_TOKEN]

Endpoints:
  - name: customers
    path: /customers
    http_method: GET
    
  - name: orders
    path: /orders
    http_method: GET
    params:
      start_date: "{{ config['start_date'] }}"
```

#### T·ªáp ngu·ªìn (CSV)

**Tr∆∞·ªùng h·ª£p s·ª≠ d·ª•ng**: Nh·∫≠p t·ªáp CSV

**C·∫•u h√¨nh:**

```yaml
Dataset Name: sales_data
URL: https://storage.example.com/sales.csv
Format: CSV
Provider:
  Storage: HTTPS
  User Provided Storage:
    URL: https://storage.example.com/sales.csv
```

#### Ngu·ªìn chung

| Ngu·ªìn | Tr∆∞·ªùng h·ª£p s·ª≠ d·ª•ng | H·ªó tr·ª£ CDC |
|--------|--------|-------------|
| **PostgreSQL** | Truy·ªán tranh giao d·ªãch | ‚úÖ C√≥ |
| **MySQL** | Truy·ªán tranh giao d·ªãch | ‚úÖ C√≥ |
| **MongoDB** | T√†i li·ªáu NoSQL | ‚úÖ C√≥ |
| **L·ª±c l∆∞·ª£ng b√°n h√†ng** | D·ªØ li·ªáu CRM | ‚ùå Kh√¥ng |
| **Google Trang t√≠nh** | B·∫£ng t√≠nh | ‚ùå Kh√¥ng |
| **S·ªçc** | D·ªØ li·ªáu thanh to√°n | ‚ùå Kh√¥ng |
| **API REST** | API t√πy ch·ªânh | ‚ùå Kh√¥ng |
| **S3** | L∆∞u tr·ªØ t·∫≠p tin | ‚ùå Kh√¥ng |

### Tr√¨nh k·∫øt n·ªëi ƒë√≠ch

#### ƒê√≠ch ƒë·∫øn c·ªßa MinIO S3

**Tr∆∞·ªùng h·ª£p s·ª≠ d·ª•ng**: L∆∞u tr·ªØ d·ªØ li·ªáu th√¥ trong h·ªì d·ªØ li·ªáu

**C·∫•u h√¨nh:**

1. ƒêi·ªÅu h∆∞·ªõng ƒë·∫øn **ƒêi·ªÉm ƒë·∫øn > ƒêi·ªÉm ƒë·∫øn m·ªõi**
2. Ch·ªçn **S3**
3. C·∫•u h√¨nh k·∫øt n·ªëi:

```yaml
S3 Bucket Name: datalake
S3 Bucket Path: airbyte-data/${NAMESPACE}/${STREAM_NAME}
S3 Bucket Region: us-east-1

# Point de terminaison MinIO
S3 Endpoint: http://minio:9000
Access Key ID: [MINIO_ROOT_USER]
Secret Access Key: [MINIO_ROOT_PASSWORD]

Output Format:
  Format Type: Parquet
  Compression: GZIP
  Block Size: 128MB
```

**Ki·ªÉm tra k·∫øt n·ªëi** ‚Üí **Thi·∫øt l·∫≠p ƒë√≠ch**

#### ƒê√≠ch PostgreSQL

**Tr∆∞·ªùng h·ª£p s·ª≠ d·ª•ng**: T·∫£i d·ªØ li·ªáu ƒë√£ chuy·ªÉn ƒë·ªïi ƒë·ªÉ ph√¢n t√≠ch

**C·∫•u h√¨nh:**

```yaml
Host: postgres
Port: 5432
Database: analytics_db
Username: analytics_user
Password: [MOT_DE_PASSE_S√âCURIS√â]
Default Schema: public

Normalization:
  Mode: Basic
  # Cr√©e tables normalis√©es depuis JSON imbriqu√©
```

#### ƒê√≠ch ƒë·∫øn Dremio

**Tr∆∞·ªùng h·ª£p s·ª≠ d·ª•ng**: T·∫£i tr·ª±c ti·∫øp v√†o kho d·ªØ li·ªáu

**C·∫•u h√¨nh:**

```yaml
Host: dremio
Port: 32010
Project: Production
Dataset: airbyte_data
Username: dremio_user
Password: [DREMIO_PASSWORD]

Connection Type: Arrow Flight
SSL: false
```

---

## K·∫øt n·ªëi

### T·∫°o k·∫øt n·ªëi

M·ªôt k·∫øt n·ªëi li√™n k·∫øt m·ªôt ngu·ªìn v·ªõi m·ªôt ƒë√≠ch.

```mermaid
sequenceDiagram
    participant S as Source
    participant A as Airbyte
    participant D as Destination
    
    S->>A: 1. Extraire donn√©es
    A->>A: 2. Appliquer transformations
    A->>D: 3. Charger donn√©es
    D->>D: 4. Normaliser (optionnel)
    A->>A: 5. Mettre √† jour √©tat
    
    Note over A: Sync termin√©e
```

#### T·ª´ng b∆∞·ªõc

1. **ƒêi·ªÅu h∆∞·ªõng ƒë·∫øn K·∫øt n·ªëi > K·∫øt n·ªëi m·ªõi**

2. **Ch·ªçn ngu·ªìn**: Ch·ªçn ngu·ªìn ƒë√£ ƒë·ªãnh c·∫•u h√¨nh (v√≠ d·ª•: PostgreSQL)

3. **Ch·ªçn ƒë√≠ch**: Ch·ªçn ƒë√≠ch ƒë·∫øn (v√≠ d·ª•: MinIO S3)

4. **ƒê·ªãnh c·∫•u h√¨nh ƒë·ªìng b·ªô h√≥a**:

```yaml
Nom Connexion: PostgreSQL ‚Üí MinIO
Fr√©quence R√©plication: Every 24 hours
Namespace Destination: Custom
  Format Namespace: production_${SOURCE_NAMESPACE}

Streams:
  - customers
    Mode Sync: Full Refresh | Overwrite
    Champ Curseur: updated_at
    Cl√© Primaire: customer_id
    
  - orders
    Mode Sync: Incremental | Append
    Champ Curseur: created_at
    Cl√© Primaire: order_id
    
  - products
    Mode Sync: Full Refresh | Overwrite
    Cl√© Primaire: product_id
```

5. **C·∫•u h√¨nh chu·∫©n h√≥a** (t√πy ch·ªçn):

```yaml
Normalization:
  Enable: true
  Option: Basic Normalization
  # Convertit JSON imbriqu√© en tables plates
```

6. **Ki·ªÉm tra k·∫øt n·ªëi** ‚Üí **Thi·∫øt l·∫≠p k·∫øt n·ªëi**

### C√°c ch·∫ø ƒë·ªô ƒë·ªìng b·ªô h√≥a

| Th·ªùi trang | M√¥ t·∫£ | Tr∆∞·ªùng h·ª£p s·ª≠ d·ª•ng |
|------|-------------|-------------|
| **L√†m m·ªõi ho√†n to√†n\| Ghi ƒë√®** | Thay th·∫ø t·∫•t c·∫£ d·ªØ li·ªáu | B·∫£ng k√≠ch th∆∞·ªõc |
| **L√†m m·ªõi ho√†n to√†n\| N·ªëi** | Th√™m t·∫•t c·∫£ h·ªì s∆° | Theo d√µi l·ªãch s·ª≠ |
| **Gia tƒÉng\| N·ªëi** | Th√™m b·∫£n ghi m·ªõi/c·∫≠p nh·∫≠t | B·∫£ng s·ª± ki·ªán |
| **Gia tƒÉng\| ƒê√£ kh·∫•u tr·ª´** | C·∫≠p nh·∫≠t h·ªì s∆° hi·ªán c√≥ | SCD Lo·∫°i 1 |

### L·∫≠p k·∫ø ho·∫°ch

**T√πy ch·ªçn t·∫ßn s·ªë:**
- **Th·ªß c√¥ng**: K√≠ch ho·∫°t th·ªß c√¥ng
- **H√†ng gi·ªù**: H√†ng gi·ªù
- **H√†ng ng√†y**: 24 gi·ªù m·ªôt l·∫ßn (ghi r√µ th·ªùi gian)
- **H√†ng tu·∫ßn**: C√°c ng√†y c·ª• th·ªÉ trong tu·∫ßn
- **Cron**: L·∫≠p l·ªãch t√πy ch·ªânh (v√≠ d·ª•: `0 2 * * *`)

**V√≠ d·ª• v·ªÅ l·ªãch tr√¨nh:**
```yaml
# Toutes les 6 heures
Cron: 0 */6 * * *

# Jours de semaine √† 2h du matin
Cron: 0 2 * * 1-5

# Premier jour du mois
Cron: 0 0 1 * *
```

---

## Chuy·ªÉn ƒë·ªïi d·ªØ li·ªáu

### Chu·∫©n h√≥a c∆° b·∫£n

Airbyte bao g·ªìm **Chu·∫©n h√≥a c∆° b·∫£n** b·∫±ng c√°ch s·ª≠ d·ª•ng dbt:

**C√¥ng vi·ªác c√¥ ·∫•y l√†m:**
- Chuy·ªÉn ƒë·ªïi JSON l·ªìng nhau th√†nh b·∫£ng ph·∫≥ng
- T·∫°o b·∫£ng `_airbyte_raw_*` (JSON th√¥)
- T·∫°o c√°c b·∫£ng ti√™u chu·∫©n (c√≥ c·∫•u tr√∫c)
- Th√™m c·ªôt si√™u d·ªØ li·ªáu (`_airbyte_emitted_at`, `_airbyte_normalized_at`)

**V√≠ d·ª•:**

**JSON th√¥** (`_airbyte_raw_customers`):
```json
{
  "_airbyte_ab_id": "uuid-123",
  "_airbyte_emitted_at": "2025-10-16T10:00:00Z",
  "_airbyte_data": {
    "id": 1,
    "name": "Acme Corp",
    "contact": {
      "email": "info@acme.com",
      "phone": "+1234567890"
    },
    "addresses": [
      {"type": "billing", "city": "New York"},
      {"type": "shipping", "city": "Boston"}
    ]
  }
}
```

**B·∫£ng ti√™u chu·∫©n:**

`customers`:
```sql
id | name | contact_email | contact_phone | _airbyte_normalized_at
1 | Acme Corp | info@acme.com | +1234567890 | 2025-10-16 10:05:00
```

`customers_addresses`:
```sql
_airbyte_customers_hashid | type | city
hash-123 | billing | New York
hash-123 | shipping | Boston
```

### Chuy·ªÉn ƒë·ªïi t√πy ch·ªânh (dbt)

ƒê·ªëi v·ªõi c√°c ph√©p bi·∫øn ƒë·ªïi n√¢ng cao, h√£y s·ª≠ d·ª•ng dbt:

1. **T·∫Øt t√≠nh nƒÉng chu·∫©n h√≥a Airbyte**
2. **T·∫°o m√¥ h√¨nh dbt** b·∫£ng tham chi·∫øu `_airbyte_raw_*`
3. **Ch·∫°y dbt** sau khi ƒë·ªìng b·ªô Airbyte

**V√≠ d·ª• v·ªÅ m√¥ h√¨nh dbt:**
```sql
-- models/staging/stg_customers.sql
with source as (
    select * from {{ source('airbyte_raw', '_airbyte_raw_customers') }}
),

parsed as (
    select
        _airbyte_ab_id,
        _airbyte_emitted_at,
        (_airbyte_data->>'id')::int as customer_id,
        _airbyte_data->>'name' as customer_name,
        _airbyte_data->'contact'->>'email' as email,
        _airbyte_data->'contact'->>'phone' as phone
    from source
)

select * from parsed
```

---

## Gi√°m s√°t

### Tr·∫°ng th√°i ƒë·ªìng b·ªô h√≥a

**Giao di·ªán web c·ªßa b·∫£ng ƒëi·ªÅu khi·ªÉn:**
- **K·∫øt n·ªëi**: Xem t·∫•t c·∫£ c√°c k·∫øt n·ªëi
- **L·ªãch s·ª≠ ƒë·ªìng b·ªô**: C√¥ng vi·ªác ƒë·ªìng b·ªô h√≥a tr∆∞·ªõc ƒë√¢y
- **Nh·∫≠t k√Ω ƒë·ªìng b·ªô**: Nh·∫≠t k√Ω chi ti·∫øt cho m·ªói c√¥ng vi·ªác

**Ch·ªâ b√°o tr·∫°ng th√°i:**
- üü¢ **Th√†nh c√¥ng**: ƒê·ªìng b·ªô h√≥a ho√†n t·∫•t th√†nh c√¥ng
- üî¥ **Kh√¥ng th√†nh c√¥ng**: ƒê·ªìng b·ªô h√≥a kh√¥ng th√†nh c√¥ng (ki·ªÉm tra nh·∫≠t k√Ω)
- üü° **ƒêang ch·∫°y**: ƒêang ƒë·ªìng b·ªô h√≥a
- ‚ö™ **ƒê√£ h·ªßy**: Ng∆∞·ªùi d√πng ƒë√£ h·ªßy ƒë·ªìng b·ªô h√≥a

### Nh·∫≠t k√Ω

**Xem nh·∫≠t k√Ω ƒë·ªìng b·ªô h√≥a:**
```bash
# Logs serveur Airbyte
docker-compose -f docker-compose-airbyte.yml logs airbyte-server

# Logs worker (ex√©cution sync r√©elle)
docker-compose -f docker-compose-airbyte.yml logs airbyte-worker

# Logs job sp√©cifique
# Disponible dans Interface Web: Connections > [Connection] > Job History > [Job]
```

### S·ªë li·ªáu

**C√°c s·ªë li·ªáu ch√≠nh c·∫ßn theo d√µi:**
- **B·∫£n ghi ƒë∆∞·ª£c ƒë·ªìng b·ªô h√≥a**: S·ªë l∆∞·ª£ng b·∫£n ghi tr√™n m·ªói l·∫ßn ƒë·ªìng b·ªô h√≥a
- **Byte ƒë∆∞·ª£c ƒë·ªìng b·ªô h√≥a**: Kh·ªëi l∆∞·ª£ng d·ªØ li·ªáu ƒë∆∞·ª£c truy·ªÅn
- **Th·ªùi l∆∞·ª£ng ƒë·ªìng b·ªô h√≥a**: Th·ªùi gian th·ª±c hi·ªán cho m·ªói l·∫ßn ƒë·ªìng b·ªô h√≥a
- **T·ª∑ l·ªá th·∫•t b·∫°i**: Ph·∫ßn trƒÉm ƒë·ªìng b·ªô h√≥a kh√¥ng th√†nh c√¥ng

**S·ªë li·ªáu xu·∫•t kh·∫©u:**
```bash
# API Airbyte
curl -X GET "http://localhost:8001/api/v1/jobs/list" \
  -H "Content-Type: application/json" \
  -d '{
    "configTypes": ["sync"],
    "configId": "connection-id"
  }'
```

### C·∫£nh b√°o

**ƒê·ªãnh c·∫•u h√¨nh c·∫£nh b√°o** trong **C√†i ƒë·∫∑t > Th√¥ng b√°o**:

```yaml
Type Notification: Slack
URL Webhook: https://hooks.slack.com/services/VOTRE/WEBHOOK/URL

√âv√©nements:
  - √âchec Sync
  - Succ√®s Sync (optionnel)
  - Connexion D√©sactiv√©e

Conditions:
  - Seuil √©chec: 3 √©checs cons√©cutifs
```

---

## C√°ch s·ª≠ d·ª•ng API

### X√°c th·ª±c

```bash
# Pas d'authentification requise pour localhost
# Pour production, configurez auth dans docker-compose-airbyte.yml
```

### L·ªánh g·ªçi API ph·ªï bi·∫øn

#### Li·ªát k√™ ngu·ªìn

```bash
curl -X POST "http://localhost:8001/api/v1/sources/list" \
  -H "Content-Type: application/json" \
  -d '{
    "workspaceId": "workspace-id"
  }'
```

#### T·∫°o k·∫øt n·ªëi

```bash
curl -X POST "http://localhost:8001/api/v1/connections/create" \
  -H "Content-Type: application/json" \
  -d '{
    "sourceId": "source-id",
    "destinationId": "destination-id",
    "syncCatalog": {
      "streams": [
        {
          "stream": {
            "name": "customers",
            "jsonSchema": {...}
          },
          "config": {
            "syncMode": "incremental",
            "destinationSyncMode": "append",
            "cursorField": ["updated_at"]
          }
        }
      ]
    },
    "schedule": {
      "units": 24,
      "timeUnit": "hours"
    }
  }'
```

#### K√≠ch ho·∫°t ƒë·ªìng b·ªô h√≥a

```bash
curl -X POST "http://localhost:8001/api/v1/connections/sync" \
  -H "Content-Type: application/json" \
  -d '{
    "connectionId": "connection-id"
  }'
```

#### Nh·∫≠n tr·∫°ng th√°i c√¥ng vi·ªác

```bash
curl -X POST "http://localhost:8001/api/v1/jobs/get" \
  -H "Content-Type: application/json" \
  -d '{
    "id": "job-id"
  }'
```

---

## T√≠ch h·ª£p v·ªõi Dremio

### Quy tr√¨nh l√†m vi·ªác

```mermaid
sequenceDiagram
    participant Src as Source Donn√©es
    participant Ab as Airbyte
    participant S3 as MinIO S3
    participant Dr as Dremio
    participant Dbt as dbt
    
    Src->>Ab: 1. Extraire donn√©es
    Ab->>S3: 2. Charger vers S3 (Parquet)
    S3->>Dr: 3. Dremio lit S3
    Dr->>Dbt: 4. dbt transforme
    Dbt->>Dr: 5. √âcrire r√©sultats
    Dr->>Dr: 6. Couche requ√™te pr√™te
```

### C√°c b∆∞·ªõc c·∫•u h√¨nh

1. **C·∫•u h√¨nh Airbyte ƒë·ªÉ s·∫°c v√†o MinIO S3** (xem b√™n tr√™n)

2. **Th√™m ngu·ªìn S3 v√†o Dremio:**

```sql
-- Dans Interface Dremio: Sources > Add Source > S3
Nom Source: AirbyteData
Authentication: AWS Access Key
Cl√© Acc√®s: [MINIO_ROOT_USER]
Cl√© Secr√®te: [MINIO_ROOT_PASSWORD]
Chemin Racine: /
Propri√©t√©s Connexion:
  fs.s3a.endpoint: minio:9000
  fs.s3a.path.style.access: true
  dremio.s3.compat: true
```

3. **Truy v·∫•n d·ªØ li·ªáu Airbyte trong Dremio:**

```sql
-- Parcourir structure S3
SELECT * FROM AirbyteData.datalake."airbyte-data"

-- Requ√™te table sp√©cifique
SELECT *
FROM AirbyteData.datalake."airbyte-data".production_public.customers
LIMIT 100
```

4. **T·∫°o b·ªô d·ªØ li·ªáu ·∫£o Dremio:**

```sql
CREATE VDS airbyte_customers AS
SELECT
  id as customer_id,
  name as customer_name,
  contact_email as email,
  contact_phone as phone,
  _airbyte_emitted_at as last_updated
FROM AirbyteData.datalake."airbyte-data".production_public.customers
```

5. **S·ª≠ d·ª•ng trong c√°c m√¥ h√¨nh dbt:**

```yaml
# dbt/models/sources.yml
sources:
  - name: airbyte
    schema: AirbyteData.datalake."airbyte-data".production_public
    tables:
      - name: customers
      - name: orders
      - name: products
```

---

## C√°c ph∆∞∆°ng ph√°p hay nh·∫•t

### Hi·ªáu su·∫•t

1. **S·ª≠ d·ª•ng ƒê·ªìng b·ªô h√≥a gia tƒÉng** b·∫•t c·ª© khi n√†o c√≥ th·ªÉ
2. **L√™n l·ªãch ƒë·ªìng b·ªô trong gi·ªù th·∫•p ƒëi·ªÉm**
3. **S·ª≠ d·ª•ng ƒë·ªãnh d·∫°ng Parquet** ƒë·ªÉ n√©n t·ªët h∆°n
4. **Ph√¢n v√πng c√°c b·∫£ng l·ªõn** theo ng√†y
5. **Gi√°m s√°t vi·ªác s·ª≠ d·ª•ng t√†i nguy√™n** v√† ƒëi·ªÅu ch·ªânh gi·ªõi h·∫°n

### Ch·∫•t l∆∞·ª£ng d·ªØ li·ªáu

1. **B·∫≠t x√°c th·ª±c d·ªØ li·ªáu** trong tr√¨nh k·∫øt n·ªëi ngu·ªìn
2. **S·ª≠ d·ª•ng kh√≥a ch√≠nh** ƒë·ªÉ ph√°t hi·ªán c√°c b·∫£n sao
3. **ƒê·ªãnh c·∫•u h√¨nh c·∫£nh b√°o** khi c√≥ l·ªói ƒë·ªìng b·ªô h√≥a
4. **Theo d√µi ƒë·ªô m·ªõi c·ªßa d·ªØ li·ªáu** s·ªë li·ªáu
5. **Th·ª±c hi·ªán ki·ªÉm tra dbt** tr√™n d·ªØ li·ªáu th√¥

### B·∫£o v·ªá

1. **S·ª≠ d·ª•ng m√£ ƒë·ªãnh danh ch·ªâ ƒë·ªçc** cho ngu·ªìn
2. **L∆∞u tr·ªØ b√≠ m·∫≠t** trong c√°c bi·∫øn m√¥i tr∆∞·ªùng
3. **B·∫≠t SSL/TLS** cho c√°c k·∫øt n·ªëi
4. **Gia h·∫°n s·ªë nh·∫≠n d·∫°ng c·ªßa b·∫°n** th∆∞·ªùng xuy√™n
5. **Ki·ªÉm tra nh·∫≠t k√Ω truy c·∫≠p** ƒë·ªãnh k·ª≥

### T·ªëi ∆∞u h√≥a chi ph√≠

1. **S·ª≠ d·ª•ng t√≠nh nƒÉng n√©n** (GZIP, SNAPPY)
2. **D·ªØ li·ªáu tr√πng l·∫∑p** t·∫°i ngu·ªìn
3. **L∆∞u tr·ªØ d·ªØ li·ªáu c≈©** v√†o kho l·∫°nh
4. **Theo d√µi t·∫ßn s·ªë ƒë·ªìng b·ªô** so v·ªõi y√™u c·∫ßu
5. **L√†m s·∫°ch d·ªØ li·ªáu ƒë·ªìng b·ªô h√≥a kh√¥ng th√†nh c√¥ng**

---

## Kh·∫Øc ph·ª•c s·ª± c·ªë

### C√°c v·∫•n ƒë·ªÅ th∆∞·ªùng g·∫∑p

#### L·ªói ƒë·ªìng b·ªô h√≥a: H·∫øt th·ªùi gian k·∫øt n·ªëi

**Tri·ªáu ch·ª©ng:**
```
Failed to connect to source: Connection timeout
```

**Gi·∫£i ph√°p:**
```bash
# V√©rifier connectivit√© r√©seau
docker exec airbyte-worker ping postgres

# V√©rifier r√®gles pare-feu
# V√©rifier h√¥te/port source dans configuration
```

#### L·ªói h·∫øt b·ªô nh·ªõ

**Tri·ªáu ch·ª©ng:**
```
OOMKilled: Container exceeded memory limit
```

**Gi·∫£i ph√°p:**
```yaml
# Augmenter limites m√©moire dans docker-compose-airbyte.yml
services:
  airbyte-worker:
    environment:
      - JOB_MAIN_CONTAINER_MEMORY_LIMIT=2Gi
      - JOB_MAIN_CONTAINER_MEMORY_REQUEST=1Gi
```

#### Chu·∫©n h√≥a kh√¥ng th√†nh c√¥ng

**Tri·ªáu ch·ª©ng:**
```
Normalization failed: dbt compilation error
```

**Gi·∫£i ph√°p:**
```bash
# V√©rifier logs dbt
docker-compose -f docker-compose-airbyte.yml logs airbyte-worker | grep dbt

# D√©sactiver normalisation et utiliser dbt personnalis√©
# Meilleur contr√¥le sur logique transformation
```

#### Hi·ªáu su·∫•t ƒë·ªìng b·ªô ch·∫≠m

**Ch·∫©n ƒëo√°n:**
```bash
# V√©rifier logs sync pour goulot d'√©tranglement
# Causes courantes:
# - Grand volume donn√©es
# - Requ√™te source lente
# - Latence r√©seau
# - Ressources insuffisantes
```

**Gi·∫£i ph√°p:**
- TƒÉng t·∫ßn s·ªë ƒë·ªìng b·ªô gia tƒÉng
- Th√™m ch·ªâ m·ª•c v√†o tr∆∞·ªùng con tr·ªè
- S·ª≠ d·ª•ng CDC cho c√°c ngu·ªìn th·ªùi gian th·ª±c
- Quy m√¥ ngu·ªìn l·ª±c c√¥ng nh√¢n

---

## Ch·ªß ƒë·ªÅ n√¢ng cao

### Tr√¨nh k·∫øt n·ªëi t√πy ch·ªânh

X√¢y d·ª±ng tr√¨nh k·∫øt n·ªëi t√πy ch·ªânh v·ªõi Airbyte CDK:

```bash
# Cloner mod√®le connecteur
git clone https://github.com/airbytehq/airbyte.git
cd airbyte/airbyte-integrations/connector-templates/python

# Cr√©er nouveau connecteur
./create_connector.sh MyCustomAPI

# Impl√©menter logique connecteur
# √âditer source.py, spec.yaml, schemas/

# Tester localement
python main.py check --config secrets/config.json
python main.py discover --config secrets/config.json
python main.py read --config secrets/config.json --catalog integration_tests/configured_catalog.json
```

### ƒêi·ªÅu ph·ªëi API

T·ª± ƒë·ªông h√≥a Airbyte b·∫±ng Python:

```python
import requests

AIRBYTE_API = "http://localhost:8001/api/v1"

def trigger_sync(connection_id: str):
    """D√©clencher sync manuelle pour connexion"""
    response = requests.post(
        f"{AIRBYTE_API}/connections/sync",
        json={"connectionId": connection_id}
    )
    return response.json()

def get_sync_status(job_id: str):
    """V√©rifier statut job sync"""
    response = requests.post(
        f"{AIRBYTE_API}/jobs/get",
        json={"id": job_id}
    )
    return response.json()

# Utilisation
job = trigger_sync("my-connection-id")
status = get_sync_status(job["job"]["id"])
print(f"Statut sync: {status['job']['status']}")
```

---

## T√†i nguy√™n

### T√†i li·ªáu

- **T√†i li·ªáu Airbyte**: https://docs.airbyte.com
- **Danh m·ª•c ƒë·∫ßu n·ªëi**: https://docs.airbyte.com/integrations
- **Tham kh·∫£o API**: https://airbyte-public-api-docs.s3.us-east-2.amazonaws.com/rapidoc-api-docs.html

### C·ªông ƒë·ªìng

- **Slack**: https://slack.airbyte.io
- **GitHub**: https://github.com/airbytehq/airbyte
- **Di·ªÖn ƒë√†n**: https://discuss.airbyte.io

---

## C√°c b∆∞·ªõc ti·∫øp theo

Sau khi c·∫•u h√¨nh Airbyte:

1. **Thi·∫øt l·∫≠p Dremio** - [H∆∞·ªõng d·∫´n thi·∫øt l·∫≠p Dremio](dremio-setup.md)
2. **T·∫°o m√¥ h√¨nh dbt** - [H∆∞·ªõng d·∫´n ph√°t tri·ªÉn dbt](dbt-development.md)
3. **X√¢y d·ª±ng b·∫£ng th√¥ng tin** - [H∆∞·ªõng d·∫´n v·ªÅ b·∫£ng th√¥ng tin Superset](superset-dashboards.md)
4. **Ch·∫•t l∆∞·ª£ng m√†n h√¨nh** - [H∆∞·ªõng d·∫´n ch·∫•t l∆∞·ª£ng d·ªØ li·ªáu](data-quality.md)

---

**Phi√™n b·∫£n h∆∞·ªõng d·∫´n t√≠ch h·ª£p Airbyte**: 3.2.0  
**C·∫≠p nh·∫≠t l·∫ßn cu·ªëi**: Ng√†y 16 th√°ng 10 nƒÉm 2025  
**ƒê∆∞·ª£c duy tr√¨ b·ªüi**: Nh√≥m n·ªÅn t·∫£ng d·ªØ li·ªáu